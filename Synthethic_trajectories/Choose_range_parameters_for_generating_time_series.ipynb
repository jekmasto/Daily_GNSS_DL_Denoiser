{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3e67e9ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-10 16:25:22.779868: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-07-10 16:25:22.847741: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-07-10 16:25:22.849905: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2023-07-10 16:25:22.849913: I tensorflow/compiler/xla/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2023-07-10 16:25:23.262879: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2023-07-10 16:25:23.262913: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2023-07-10 16:25:23.262917: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-10 16:25:23.756949: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
      "2023-07-10 16:25:23.756973: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: giacomo-Z590-AORUS-MASTER\n",
      "2023-07-10 16:25:23.756976: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: giacomo-Z590-AORUS-MASTER\n",
      "2023-07-10 16:25:23.757018: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: 525.116.4\n",
      "2023-07-10 16:25:23.757029: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 525.116.4\n",
      "2023-07-10 16:25:23.757031: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:310] kernel version seems to match DSO: 525.116.4\n"
     ]
    }
   ],
   "source": [
    "import sys ,glob, os,pickle,random\n",
    "import numpy as np\n",
    "import datetime as dt\n",
    "sys.path.append('/home/giacomo/Documents/Denoiser_GPS/sharing_gratsid_tf_in_development')\n",
    "sys.path.append('/home/giacomo/Documents/Step_model')\n",
    "sys.path.append('/home/giacomo/Documents/Denoiser_GPS/Denoiser_code')\n",
    "from funcs_4_DL_resids import *\n",
    "from gratsid_tf_gpu_functions_SHARED import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3b407db6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10%\n",
      "[0.18801744]\n",
      "20%\n",
      "[0.22452118]\n",
      "30%\n",
      "[0.22452118]\n",
      "40%\n",
      "[0.28170884]\n",
      "50%\n",
      "[0.28170884]\n",
      "60%\n",
      "[0.32102071]\n",
      "70%\n",
      "[0.32102071]\n",
      "80%\n",
      "[0.32102071]\n",
      "90%\n",
      "[2.90863324]\n",
      "Max amplitude for seasonals:  [2.90863324]\n",
      "Max amplitude for transients:  [30.30877162]\n",
      "Max amplitude for trend:  [59.60290465]\n"
     ]
    }
   ],
   "source": [
    "# components=['E/' ] #'E/','N/' #'U/'\n",
    "components=['U/']\n",
    "soln_folder_path='/home/giacomo/Documents/Denoiser_GPS/Wordwide_dataset/sols_tables_'\n",
    "data_folder_path='/home/giacomo/Documents/Denoiser_GPS/Wordwide_dataset/data_bank/'\n",
    "names=id_names_npz(soln_folder_path+components[0])\n",
    "gen_jjj = np.vectorize(lambda x,y,z: dt.date.toordinal(dt.date(x,y,z)))\n",
    "name=names[0]\n",
    "\n",
    "sa_coeff=0\n",
    "tr_coeff=0\n",
    "trans_coeff=0\n",
    "\n",
    "for c in range(len(components)):\n",
    "\n",
    "    ############ finally build ############\n",
    "    soln_folder=soln_folder_path+components[c]\n",
    "    sol_path = soln_folder+name+'.npz'\n",
    "    options = np.load(sol_path,allow_pickle=True)['options']\n",
    "    options = options.item()\n",
    "    data_cols = np.load(sol_path)['data_cols']\n",
    "    \n",
    "    ten_step=10\n",
    "    ########## Allocate  ##########\n",
    "    for i in range(len(names)):\n",
    "        name=names[i]\n",
    "        sol_path = soln_folder+name+'.npz'\n",
    "        data_path = data_folder_path+name+'.txt'\n",
    "    \n",
    "        ## loading in the data and the corresponding gratsid solution table\n",
    "        data = np.loadtxt(data_path)\n",
    "        perm = list(np.load(sol_path,allow_pickle=True)['perm'])\n",
    "        sols = list(np.load(sol_path,allow_pickle=True)['sols'])\n",
    "    \n",
    "        ## converting time to python datetime integer and isolating the fit directional components\n",
    "        t = gen_jjj(data[:,0].astype(int),data[:,1].astype(int),data[:,2].astype(int))\n",
    "        y = data[:,data_cols] ## columns 3,4,5  (in python indexing) are E,N,U\n",
    "        \n",
    "        signal = fit_decompose(t,y,None,options['tik_mul'], \\\n",
    "                sols,np.asarray(perm),options['bigTs'],options['Fs']) \n",
    "        \n",
    "        table = np.vstack([perm,sols[-1][-1]])\n",
    "        G, m_keys = assemble_G_return_keys(t,table,options['bigTs'],options['Fs'])\n",
    "\n",
    "        residual,residual_val,weighted_residual_val,m \\\n",
    "            = single_fit_predict_tf(G_in=G,y_in=y,err_in=None,tik_mul=options['tik_mul'])\n",
    "        \n",
    "        ## This is the maximum coefficient for seasonal a annual amplitudes\n",
    "        if max(m[np.where(m_keys==2)])>sa_coeff:\n",
    "            sa_coeff=max(m[np.where(m_keys==2)])\n",
    "            \n",
    "        if max(m[np.where(m_keys==1)])>tr_coeff:\n",
    "            tr_coeff=max(m[np.where(m_keys==1)])\n",
    "        \n",
    "        if 3 in m_keys:\n",
    "            if max(m[np.where(m_keys==3)])>trans_coeff:\n",
    "                trans_coeff=max(m[np.where(m_keys==3)])\n",
    "            \n",
    "        perc=i*100/len(names)\n",
    "        if perc>ten_step:\n",
    "            print(str(round(perc))+'%')\n",
    "            ten_step+=10\n",
    "            print(sa_coeff)\n",
    "            \n",
    "print('Max amplitude for seasonals: ',sa_coeff)\n",
    "print('Max amplitude for transients: ',trans_coeff)\n",
    "print('Max amplitude for trend: ',tr_coeff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "80c9421b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1795.5096329])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tr_coeff"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
